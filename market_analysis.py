# market_analysis.py

import yfinance as yf
import pandas as pd
import streamlit as st
from datetime import date, timedelta
import requests

# ----------------------------------------------------
# Function to get S&P 500 Symbols from Wikipedia
# ----------------------------------------------------
@st.cache_data(ttl=timedelta(days=1)) # Cache symbols for 1 day
def get_sp500_symbols():
    """
    Fetches the latest S&P 500 component list from Wikipedia.
    """
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    
    # CRITICAL FIX: Add User-Agent to bypass 403 Forbidden error
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        st.info("å°è¯•ä» Wikipedia è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨...")
        
        # Use requests to download content with headers
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() 

        # Use pandas to read the HTML content (response.text)
        tables = pd.read_html(response.text)
        
        sp500_table = None
        for table in tables:
            if 'Symbol' in table.columns and 'Security' in table.columns:
                sp500_table = table
                break
        
        if sp500_table is None:
            st.error("æ— æ³•åœ¨ Wikipedia é¡µé¢æ‰¾åˆ° S&P 500 æˆåˆ†è‚¡è¡¨æ ¼ã€‚")
            return []

        symbols = sp500_table['Symbol'].tolist()
        
        st.success(f"æˆåŠŸè·å– {len(symbols)} ä¸ª S&P 500 æˆåˆ†è‚¡ä»£ç ã€‚")
        return symbols

    except requests.exceptions.HTTPError as e:
        st.error(f"è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨å¤±è´¥ (HTTP é”™è¯¯: {e})ã€‚è¯·æ£€æŸ¥ User-Agent æˆ–ç›®æ ‡ URLã€‚")
        return []
    except requests.exceptions.RequestException as e:
        st.error(f"è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨å¤±è´¥ (ç½‘ç»œæˆ–è¶…æ—¶é”™è¯¯): {e}")
        return []
    except Exception as e:
        st.error(f"è§£æ S&P 500 æˆåˆ†è‚¡åˆ—è¡¨å¤±è´¥: {e}")
        return []


# ----------------------------------------------------
# Function to download stock data
# ----------------------------------------------------
@st.cache_data(ttl=timedelta(hours=6)) # Cache stock data for 6 hours
def get_sp500_stock_data():
    """Downloads historical price data for all S&P 500 symbols."""
    
    sp500_symbols = get_sp500_symbols() 
    
    if not sp500_symbols:
        st.warning("æœªèƒ½è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨ï¼Œæ— æ³•ä¸‹è½½è‚¡ç¥¨æ•°æ®ã€‚")
        return None

    end_date = date.today()
    start_date = end_date - timedelta(days=90) # Need 90 days for 20 DMA calculation buffer

    st.write(f"ğŸ“ˆ æ­£åœ¨ä¸‹è½½ {len(sp500_symbols)} æ”¯ S&P 500 æˆåˆ†è‚¡å†å²ä»·æ ¼æ•°æ®... (åˆæ¬¡è¿è¡Œè¾ƒæ…¢)")
    
    try:
        # ä½¿ç”¨ concurrent downloads (threads) æ¥å¤„ç†å¤§ç¬¦å·åˆ—è¡¨
        data = yf.download(
            tickers=sp500_symbols,
            start=start_date,
            end=end_date,
            group_by='ticker',
            progress=False, 
            auto_adjust=True, 
            repair=True,
            # --- å…³é”®ä¿®å¤ï¼šç§»é™¤ 'max_workers' å’Œ 'threads' å‚æ•° ---
            # yfinance é»˜è®¤ä¼šè¿›è¡Œçº¿ç¨‹ä¸‹è½½ï¼Œä¸éœ€è¦é¢å¤–è®¾ç½®è¿™äº›å‚æ•°
        )
        
        # Filter out tickers that failed to download or are entirely empty
        valid_tickers = [ticker for ticker in sp500_symbols if (ticker, 'Close') in data.columns]
        
        if len(valid_tickers) < len(sp500_symbols):
            st.warning(f"æ³¨æ„: {len(sp500_symbols) - len(valid_tickers)} æ”¯è‚¡ç¥¨æ•°æ®æœªèƒ½å®Œå…¨ä¸‹è½½ã€‚")
            
        return data

    except Exception as e:
        st.error(f"ä¸‹è½½S&P 500æ•°æ®å¤±è´¥: {e}")
        return None


# ----------------------------------------------------
# Function to calculate market breadth
# ----------------------------------------------------
def calculate_market_breadth(stock_data: pd.DataFrame):
    """
    è®¡ç®—æœ‰å¤šå°‘æˆåˆ†è‚¡çš„è‚¡ä»·ä½äº20æ—¥å’Œ60æ—¥å‡çº¿ä¸Šæ–¹ã€‚
    
    Returns:
        åŒ…å«è®¡æ•°å’Œç™¾åˆ†æ¯”çš„æ•°æ®å­—å…¸ï¼Œç°åŒ…å« 20 DMA å’Œ 60 DMA çš„ç»“æœã€‚
    """
    
    sp500_symbols = get_sp500_symbols()

    if stock_data is None or stock_data.empty or not sp500_symbols:
        return {
            "eligible_total": 0,
            "20DMA_count": 0, "20DMA_percentage": 0,
            "60DMA_count": 0, "60DMA_percentage": 0,
        }

    above_20ma_count = 0
    above_60ma_count = 0
    total_eligible_stocks = 0 

    # éå†æ¯ä¸ªè‚¡ç¥¨ä»£ç 
    for ticker in sp500_symbols:
        if (ticker, 'Close') in stock_data.columns:
            df_ticker = stock_data[ticker]['Close'].dropna()
            
            # Need at least 60 points for the 60 DMA
            if len(df_ticker) < 60:
                continue
            
            # 1. Calculate Moving Averages
            df_ticker_20ma = df_ticker.rolling(window=20).mean()
            df_ticker_60ma = df_ticker.rolling(window=60).mean()
            
            # 2. Get latest values
            latest_close = df_ticker.iloc[-1]
            latest_20ma = df_ticker_20ma.iloc[-1]
            latest_60ma = df_ticker_60ma.iloc[-1]
            
            if pd.isna(latest_close) or pd.isna(latest_20ma) or pd.isna(latest_60ma):
                continue

            # 3. Compare and Count
            if latest_close > latest_20ma:
                above_20ma_count += 1
            
            if latest_close > latest_60ma:
                above_60ma_count += 1
            
            total_eligible_stocks += 1
            
    # Calculate percentages
    pct_20ma = (above_20ma_count / total_eligible_stocks) * 100 if total_eligible_stocks > 0 else 0
    pct_60ma = (above_60ma_count / total_eligible_stocks) * 100 if total_eligible_stocks > 0 else 0
    
    return {
        "eligible_total": total_eligible_stocks,
        "20DMA_count": above_20ma_count, 
        "20DMA_percentage": pct_20ma,
        "60DMA_count": above_60ma_count, 
        "60DMA_percentage": pct_60ma,
    }
